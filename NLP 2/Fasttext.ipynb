{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext\n",
    "\n",
    "Para calcular vectores de palabras (embeddings), se necesita un gran corpus de texto. Dependiendo del corpus, los vectores de palabras capturarán información diferente. \n",
    "\n",
    "En este tutorial, nos centramos en los artículos de Wikipedia. \n",
    "\n",
    "\n",
    "## Data\n",
    "La descarga del corpus de Wikipedia lleva algún tiempo. Entonces, limitaremos nuestro estudio a los primeros mil millones de bytes de Wikipedia en inglés. Se pueden encontrar en el sitio web de Matt Mahoney y descargar mediante el siguiente código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mkdir data\n",
    "wget -c http://mattmahoney.net/dc/enwik9.zip -P data\n",
    "unzip data/enwik9.zip -d data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de Wikipedia contienen una gran cantidad de datos HTML / XML. Los preprocesamos con el script wikifil.pl incluido en el [github](https://github.com/facebookresearch/fastText) fastText "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "perl wikifil.pl data/enwik9 > data/fil9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar el archivo ejecutando el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ head -c 80 data/fil9\n",
    "anarchism originated as a term of abuse first used against early working class\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el texto está bien preprocesado y se puede utilizar para aprender nuestros vectores de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Modelo\n",
    "El aprendizaje de vectores de palabras sobre estos datos ahora se puede lograr con un solo comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_unsupervised('data/fil9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta que esto puede demorar una hora o mas dado que la versión en python es mas lenta y son muchisimos datos.\n",
    "\n",
    "Una vez que finalizado el entrenamiento, tenemos nuestro modelo listo para poder usar para realizar consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'of',\n",
       " 'one',\n",
       " 'zero',\n",
       " 'and',\n",
       " 'in',\n",
       " 'two',\n",
       " 'a',\n",
       " 'nine',\n",
       " 'to',\n",
       " 'is',\n",
       " 'eight',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'for',\n",
       " 'are',\n",
       " 'as',\n",
       " 'was',\n",
       " 's',\n",
       " 'with',\n",
       " 'by',\n",
       " 'from',\n",
       " 'that',\n",
       " 'on',\n",
       " 'or',\n",
       " 'it',\n",
       " 'at',\n",
       " 'his',\n",
       " 'an',\n",
       " 'he',\n",
       " 'have',\n",
       " 'which',\n",
       " 'be',\n",
       " 'this',\n",
       " 'there',\n",
       " 'age',\n",
       " 'also',\n",
       " 'has',\n",
       " 'population',\n",
       " 'not',\n",
       " 'were',\n",
       " 'who',\n",
       " 'other',\n",
       " 'had',\n",
       " 'but',\n",
       " 'years',\n",
       " 'all',\n",
       " 'km',\n",
       " 'their',\n",
       " 'out',\n",
       " 'new',\n",
       " 'city',\n",
       " 'under',\n",
       " 'first',\n",
       " 'more',\n",
       " 'its',\n",
       " 'american',\n",
       " 'county',\n",
       " 'they',\n",
       " 'mi',\n",
       " 'living',\n",
       " 'income',\n",
       " 'some',\n",
       " 'median',\n",
       " 'been',\n",
       " 'after',\n",
       " 'total',\n",
       " 'most',\n",
       " 'can',\n",
       " 'united',\n",
       " 'no',\n",
       " 'when',\n",
       " 'many',\n",
       " 'states',\n",
       " 'people',\n",
       " 'over',\n",
       " 'time',\n",
       " 'census',\n",
       " 'into',\n",
       " 'used',\n",
       " 'such',\n",
       " 'may',\n",
       " 'i',\n",
       " 'up',\n",
       " 'town',\n",
       " 'average',\n",
       " 'see',\n",
       " 'older',\n",
       " 'area',\n",
       " 'families',\n",
       " 'only',\n",
       " 'family',\n",
       " 'those',\n",
       " 'males',\n",
       " 'females',\n",
       " 'households',\n",
       " 'line',\n",
       " 'made',\n",
       " 'world',\n",
       " 'them',\n",
       " 'these',\n",
       " 'her',\n",
       " 'than',\n",
       " 'would',\n",
       " 'any',\n",
       " 'every',\n",
       " 'during',\n",
       " 'war',\n",
       " 'external',\n",
       " 'known',\n",
       " 'about',\n",
       " 'links',\n",
       " 'north',\n",
       " 'below',\n",
       " 'size',\n",
       " 'water',\n",
       " 'between',\n",
       " 'however',\n",
       " 'located',\n",
       " 'state',\n",
       " 'th',\n",
       " 'd',\n",
       " 'name',\n",
       " 'she',\n",
       " 'if',\n",
       " 'where',\n",
       " 'density',\n",
       " 'history',\n",
       " 'called',\n",
       " 'm',\n",
       " 'races',\n",
       " 'household',\n",
       " 'then',\n",
       " 'poverty',\n",
       " 'part',\n",
       " 'him',\n",
       " 'use',\n",
       " 'so',\n",
       " 'will',\n",
       " 'being',\n",
       " 'later',\n",
       " 'west',\n",
       " 'well',\n",
       " 'while',\n",
       " 'b',\n",
       " 'white',\n",
       " 'u',\n",
       " 'often',\n",
       " 'non',\n",
       " 'university',\n",
       " 'both',\n",
       " 'de',\n",
       " 'became',\n",
       " 'system',\n",
       " 'land',\n",
       " 'south',\n",
       " 'number',\n",
       " 'c',\n",
       " 'year',\n",
       " 'through',\n",
       " 'government',\n",
       " 'e',\n",
       " 't',\n",
       " 'children',\n",
       " 'john',\n",
       " 'township',\n",
       " 'present',\n",
       " 'according',\n",
       " 'national',\n",
       " 'like',\n",
       " 'since',\n",
       " 'early',\n",
       " 'century',\n",
       " 'british',\n",
       " 'high',\n",
       " 'because',\n",
       " 'english',\n",
       " 'school',\n",
       " 'life',\n",
       " 'several',\n",
       " 'music',\n",
       " 'general',\n",
       " 'n',\n",
       " 'same',\n",
       " 'including',\n",
       " 'before',\n",
       " 'together',\n",
       " 'series',\n",
       " 'now',\n",
       " 'per',\n",
       " 'x',\n",
       " 'king',\n",
       " 'each',\n",
       " 'work',\n",
       " 'very',\n",
       " 'film',\n",
       " 'you',\n",
       " 'married',\n",
       " 'even',\n",
       " 'second',\n",
       " 'although',\n",
       " 'day',\n",
       " 'female',\n",
       " 'village',\n",
       " 'african',\n",
       " 'against',\n",
       " 'born',\n",
       " 'much',\n",
       " 'native',\n",
       " 'york',\n",
       " 'list',\n",
       " 'french',\n",
       " 'until',\n",
       " 'race',\n",
       " 'long',\n",
       " 'could',\n",
       " 'group',\n",
       " 'public',\n",
       " 'large',\n",
       " 'what',\n",
       " 'units',\n",
       " 'great',\n",
       " 'form',\n",
       " 'based',\n",
       " 'another',\n",
       " 'party',\n",
       " 'pacific',\n",
       " 'example',\n",
       " 'g',\n",
       " 'game',\n",
       " 'st',\n",
       " 'still',\n",
       " 'individuals',\n",
       " 'power',\n",
       " 'end',\n",
       " 'major',\n",
       " 'alone',\n",
       " 'spread',\n",
       " 'do',\n",
       " 'f',\n",
       " 'ii',\n",
       " 'geography',\n",
       " 'river',\n",
       " 'husband',\n",
       " 'r',\n",
       " 'someone',\n",
       " 'us',\n",
       " 'best',\n",
       " 'asian',\n",
       " 'around',\n",
       " 'place',\n",
       " 'own',\n",
       " 'small',\n",
       " 'east',\n",
       " 'law',\n",
       " 'found',\n",
       " 'set',\n",
       " 'housing',\n",
       " 'german',\n",
       " 'bureau',\n",
       " 'president',\n",
       " 'death',\n",
       " 'language',\n",
       " 'international',\n",
       " 'different',\n",
       " 'black',\n",
       " 'left',\n",
       " 'order',\n",
       " 'racial',\n",
       " 'following',\n",
       " 'old',\n",
       " 'book',\n",
       " 'demographics',\n",
       " 'main',\n",
       " 'term',\n",
       " 'we',\n",
       " 'versus',\n",
       " 'home',\n",
       " 'house',\n",
       " 'way',\n",
       " 'p',\n",
       " 'man',\n",
       " 'did',\n",
       " 'capita',\n",
       " 'couples',\n",
       " 'usually',\n",
       " 'common',\n",
       " 'hispanic',\n",
       " 'makeup',\n",
       " 'named',\n",
       " 'country',\n",
       " 'residing',\n",
       " 'show',\n",
       " 'political',\n",
       " 'include',\n",
       " 'image',\n",
       " 'latino',\n",
       " 'modern',\n",
       " 'though',\n",
       " 'householder',\n",
       " 'within',\n",
       " 'islander',\n",
       " 'cdp',\n",
       " 'church',\n",
       " 'point',\n",
       " 'l',\n",
       " 'back',\n",
       " 'due',\n",
       " 'popular',\n",
       " 'members',\n",
       " 'last',\n",
       " 'air',\n",
       " 'official',\n",
       " 'january',\n",
       " 'right',\n",
       " 'march',\n",
       " 'military',\n",
       " 'times',\n",
       " 'among',\n",
       " 'using',\n",
       " 'original',\n",
       " 'company',\n",
       " 'cities',\n",
       " 'make',\n",
       " 'began',\n",
       " 'island',\n",
       " 'v',\n",
       " 'considered',\n",
       " 'given',\n",
       " 'london',\n",
       " 'band',\n",
       " 'battle',\n",
       " 'o',\n",
       " 'just',\n",
       " 'article',\n",
       " 'off',\n",
       " 'without',\n",
       " 'version',\n",
       " 'album',\n",
       " 'down',\n",
       " 'information',\n",
       " 'h',\n",
       " 'bc',\n",
       " 'released',\n",
       " 'site',\n",
       " 'england',\n",
       " 'college',\n",
       " 'location',\n",
       " 'j',\n",
       " 'october',\n",
       " 'france',\n",
       " 'become',\n",
       " 'september',\n",
       " 'june',\n",
       " 'army',\n",
       " 'important',\n",
       " 'december',\n",
       " 'sometimes',\n",
       " 'july',\n",
       " 'should',\n",
       " 'few',\n",
       " 'local',\n",
       " 'w',\n",
       " 'former',\n",
       " 'human',\n",
       " 'k',\n",
       " 'william',\n",
       " 'service',\n",
       " 'along',\n",
       " 'son',\n",
       " 'near',\n",
       " 'free',\n",
       " 'april',\n",
       " 'center',\n",
       " 'november',\n",
       " 'various',\n",
       " 'august',\n",
       " 'western',\n",
       " 'died',\n",
       " 'single',\n",
       " 'led',\n",
       " 'february',\n",
       " 'roman',\n",
       " 'period',\n",
       " 'james',\n",
       " 'central',\n",
       " 'god',\n",
       " 'control',\n",
       " 'others',\n",
       " 'george',\n",
       " 'similar',\n",
       " 'case',\n",
       " 'america',\n",
       " 'does',\n",
       " 'took',\n",
       " 'theory',\n",
       " 'late',\n",
       " 'games',\n",
       " 'said',\n",
       " 'less',\n",
       " 'television',\n",
       " 'force',\n",
       " 'men',\n",
       " 'space',\n",
       " 'park',\n",
       " 'thus',\n",
       " 'published',\n",
       " 'union',\n",
       " 'district',\n",
       " 'created',\n",
       " 'short',\n",
       " 'isbn',\n",
       " 'team',\n",
       " 'built',\n",
       " 'word',\n",
       " 'science',\n",
       " 'little',\n",
       " 'written',\n",
       " 'works',\n",
       " 'development',\n",
       " 'never',\n",
       " 'support',\n",
       " 'player',\n",
       " 'character',\n",
       " 'computer',\n",
       " 'must',\n",
       " 'court',\n",
       " 'famous',\n",
       " 'how',\n",
       " 'systems',\n",
       " 'take',\n",
       " 'held',\n",
       " 'community',\n",
       " 'father',\n",
       " 'side',\n",
       " 'again',\n",
       " 'third',\n",
       " 'european',\n",
       " 'generally',\n",
       " 'groups',\n",
       " 'births',\n",
       " 'canada',\n",
       " 'song',\n",
       " 'red',\n",
       " 'good',\n",
       " 'kingdom',\n",
       " 'himself',\n",
       " 'rather',\n",
       " 'story',\n",
       " 'rock',\n",
       " 'art',\n",
       " 'la',\n",
       " 'star',\n",
       " 'either',\n",
       " 'came',\n",
       " 'having',\n",
       " 'social',\n",
       " 'lake',\n",
       " 'minister',\n",
       " 'field',\n",
       " 'once',\n",
       " 'member',\n",
       " 'body',\n",
       " 'today',\n",
       " 'my',\n",
       " 'seen',\n",
       " 'books',\n",
       " 'references',\n",
       " 'northern',\n",
       " 'act',\n",
       " 'play',\n",
       " 'europe',\n",
       " 'germany',\n",
       " 'california',\n",
       " 'covered',\n",
       " 'council',\n",
       " 'played',\n",
       " 'page',\n",
       " 'earth',\n",
       " 'current',\n",
       " 'charles',\n",
       " 'uk',\n",
       " 'forces',\n",
       " 'role',\n",
       " 'society',\n",
       " 'website',\n",
       " 'open',\n",
       " 'japanese',\n",
       " 'further',\n",
       " 'light',\n",
       " 'sea',\n",
       " 'title',\n",
       " 'areas',\n",
       " 'live',\n",
       " 'region',\n",
       " 'fact',\n",
       " 'countries',\n",
       " 'class',\n",
       " 'radio',\n",
       " 'upon',\n",
       " 'especially',\n",
       " 'next',\n",
       " 'million',\n",
       " 'result',\n",
       " 'china',\n",
       " 'none',\n",
       " 'standard',\n",
       " 'type',\n",
       " 'level',\n",
       " 'top',\n",
       " 'won',\n",
       " 'royal',\n",
       " 'full',\n",
       " 'source',\n",
       " 'deaths',\n",
       " 'means',\n",
       " 'special',\n",
       " 'days',\n",
       " 'young',\n",
       " 'towns',\n",
       " 'largest',\n",
       " 'production',\n",
       " 'robert',\n",
       " 'head',\n",
       " 'texas',\n",
       " 'style',\n",
       " 'republic',\n",
       " 'league',\n",
       " 'chinese',\n",
       " 'developed',\n",
       " 'possible',\n",
       " 'process',\n",
       " 'above',\n",
       " 'almost',\n",
       " 'produced',\n",
       " 'events',\n",
       " 'established',\n",
       " 'making',\n",
       " 'person',\n",
       " 'office',\n",
       " 'data',\n",
       " 'itself',\n",
       " 'real',\n",
       " 'middle',\n",
       " 'love',\n",
       " 'included',\n",
       " 'greek',\n",
       " 'david',\n",
       " 'com',\n",
       " 'women',\n",
       " 'empire',\n",
       " 'season',\n",
       " 're',\n",
       " 'christian',\n",
       " 'available',\n",
       " 'press',\n",
       " 'taken',\n",
       " 'movement',\n",
       " 'originally',\n",
       " 'culture',\n",
       " 'movie',\n",
       " 'me',\n",
       " 'henry',\n",
       " 'washington',\n",
       " 'san',\n",
       " 'research',\n",
       " 'far',\n",
       " 'southern',\n",
       " 'design',\n",
       " 'paul',\n",
       " 'al',\n",
       " 'final',\n",
       " 'lost',\n",
       " 'record',\n",
       " 'half',\n",
       " 'languages',\n",
       " 'program',\n",
       " 'australia',\n",
       " 'position',\n",
       " 'hand',\n",
       " 'airport',\n",
       " 'actor',\n",
       " 'instead',\n",
       " 'civil',\n",
       " 'low',\n",
       " 'education',\n",
       " 'japan',\n",
       " 'related',\n",
       " 'here',\n",
       " 'capital',\n",
       " 'formed',\n",
       " 'natural',\n",
       " 'films',\n",
       " 'places',\n",
       " 'species',\n",
       " 'eastern',\n",
       " 'run',\n",
       " 'received',\n",
       " 'building',\n",
       " 'characters',\n",
       " 'go',\n",
       " 'station',\n",
       " 'parts',\n",
       " 'view',\n",
       " 'project',\n",
       " 'economic',\n",
       " 'went',\n",
       " 'change',\n",
       " 'rights',\n",
       " 'user',\n",
       " 'code',\n",
       " 'students',\n",
       " 'spanish',\n",
       " 'map',\n",
       " 'certain',\n",
       " 'street',\n",
       " 'founded',\n",
       " 'thomas',\n",
       " 'ancient',\n",
       " 'lord',\n",
       " 'terms',\n",
       " 'range',\n",
       " 'eventually',\n",
       " 'business',\n",
       " 'least',\n",
       " 'road',\n",
       " 'news',\n",
       " 'pennsylvania',\n",
       " 'continued',\n",
       " 'canadian',\n",
       " 'post',\n",
       " 'http',\n",
       " 'whose',\n",
       " 'aircraft',\n",
       " 'soviet',\n",
       " 'prime',\n",
       " 'words',\n",
       " 'records',\n",
       " 'always',\n",
       " 'energy',\n",
       " 'model',\n",
       " 'emperor',\n",
       " 'get',\n",
       " 'too',\n",
       " 'fire',\n",
       " 'career',\n",
       " 'network',\n",
       " 'your',\n",
       " 'addition',\n",
       " 'y',\n",
       " 'richard',\n",
       " 'religious',\n",
       " 'green',\n",
       " 'traditional',\n",
       " 'video',\n",
       " 'wrote',\n",
       " 'tv',\n",
       " 'saint',\n",
       " 'sound',\n",
       " 'uploaded',\n",
       " 'come',\n",
       " 'numbers',\n",
       " 'particular',\n",
       " 'software',\n",
       " 'attack',\n",
       " 'release',\n",
       " 'historical',\n",
       " 'served',\n",
       " 'trade',\n",
       " 'note',\n",
       " 'uses',\n",
       " 'india',\n",
       " 'mother',\n",
       " 'market',\n",
       " 'throughout',\n",
       " 'action',\n",
       " 'names',\n",
       " 'moved',\n",
       " 'queen',\n",
       " 'lower',\n",
       " 'might',\n",
       " 'night',\n",
       " 'away',\n",
       " 'meaning',\n",
       " 'forms',\n",
       " 'soon',\n",
       " 'schools',\n",
       " 'hall',\n",
       " 'thought',\n",
       " 'study',\n",
       " 'www',\n",
       " 'self',\n",
       " 'football',\n",
       " 'author',\n",
       " 'foreign',\n",
       " 'text',\n",
       " 'nature',\n",
       " 'return',\n",
       " 'recent',\n",
       " 'wife',\n",
       " 'independent',\n",
       " 'anti',\n",
       " 'leader',\n",
       " 'prince',\n",
       " 'technology',\n",
       " 'particularly',\n",
       " 'despite',\n",
       " 'started',\n",
       " 'players',\n",
       " 'able',\n",
       " 'russian',\n",
       " 'described',\n",
       " 'islands',\n",
       " 'jewish',\n",
       " 'services',\n",
       " 'lead',\n",
       " 'ireland',\n",
       " 'iii',\n",
       " 'our',\n",
       " 'election',\n",
       " 'future',\n",
       " 'strong',\n",
       " 'effect',\n",
       " 'base',\n",
       " 'commonly',\n",
       " 'includes',\n",
       " 'blue',\n",
       " 'elected',\n",
       " 'killed',\n",
       " 'italian',\n",
       " 'federal',\n",
       " 'themselves',\n",
       " 'designated',\n",
       " 'co',\n",
       " 'big',\n",
       " 'novel',\n",
       " 'peter',\n",
       " 'borough',\n",
       " 'michael',\n",
       " 'true',\n",
       " 'food',\n",
       " 'actually',\n",
       " 'wikipedia',\n",
       " 'ever',\n",
       " 'appeared',\n",
       " 'outside',\n",
       " 'function',\n",
       " 'award',\n",
       " 'club',\n",
       " 'catholic',\n",
       " 'currently',\n",
       " 'followed',\n",
       " 'referred',\n",
       " 'close',\n",
       " 'miles',\n",
       " 'minnesota',\n",
       " 'museum',\n",
       " 'rule',\n",
       " 'division',\n",
       " 'association',\n",
       " 'higher',\n",
       " 'across',\n",
       " 'put',\n",
       " 'paris',\n",
       " 'industry',\n",
       " 'chief',\n",
       " 'cases',\n",
       " 'value',\n",
       " 'complete',\n",
       " 'link',\n",
       " 'beginning',\n",
       " 'features',\n",
       " 'success',\n",
       " 'writer',\n",
       " 'latin',\n",
       " 'indian',\n",
       " 'returned',\n",
       " 'province',\n",
       " 'working',\n",
       " 'irish',\n",
       " 'find',\n",
       " 'louis',\n",
       " 'material',\n",
       " 'help',\n",
       " 'introduced',\n",
       " 'musical',\n",
       " 'usa',\n",
       " 'influence',\n",
       " 'therefore',\n",
       " 'subject',\n",
       " 'front',\n",
       " 'significant',\n",
       " 'africa',\n",
       " 'designed',\n",
       " 'leading',\n",
       " 'ship',\n",
       " 'coast',\n",
       " 'speed',\n",
       " 'seat',\n",
       " 'don',\n",
       " 'valley',\n",
       " 'whether',\n",
       " 'personal',\n",
       " 'cross',\n",
       " 'media',\n",
       " 'interest',\n",
       " 'brought',\n",
       " 'structure',\n",
       " 'cause',\n",
       " 'britain',\n",
       " 'points',\n",
       " 'talk',\n",
       " 'typically',\n",
       " 'practice',\n",
       " 'governor',\n",
       " 'problems',\n",
       " 'episode',\n",
       " 'associated',\n",
       " 'problem',\n",
       " 'rate',\n",
       " 'fiction',\n",
       " 'singer',\n",
       " 'better',\n",
       " 'daughter',\n",
       " 'individual',\n",
       " 'board',\n",
       " 'gave',\n",
       " 'songs',\n",
       " 'lines',\n",
       " 'mass',\n",
       " 'nations',\n",
       " 'private',\n",
       " 'virginia',\n",
       " 'michigan',\n",
       " 'sir',\n",
       " 'money',\n",
       " 'date',\n",
       " 'brother',\n",
       " 'successful',\n",
       " 'legal',\n",
       " 'shows',\n",
       " 'police',\n",
       " 'policy',\n",
       " 'writing',\n",
       " 'grand',\n",
       " 'yet',\n",
       " 'department',\n",
       " 'parliament',\n",
       " 'literature',\n",
       " 'remained',\n",
       " 'ground',\n",
       " 'performance',\n",
       " 'simply',\n",
       " 'centre',\n",
       " 'actress',\n",
       " 'navy',\n",
       " 'months',\n",
       " 'probably',\n",
       " 'larger',\n",
       " 'widely',\n",
       " 'italy',\n",
       " 'duke',\n",
       " 'australian',\n",
       " 'car',\n",
       " 'library',\n",
       " 'reference',\n",
       " 'section',\n",
       " 'ohio',\n",
       " 'earlier',\n",
       " 'health',\n",
       " 'give',\n",
       " 'types',\n",
       " 'hill',\n",
       " 'need',\n",
       " 'director',\n",
       " 'commercial',\n",
       " 'elements',\n",
       " 'peace',\n",
       " 'evidence',\n",
       " 'key',\n",
       " 'required',\n",
       " 'sun',\n",
       " 'organization',\n",
       " 'counties',\n",
       " 'dr',\n",
       " 'bridge',\n",
       " 'allowed',\n",
       " 'limited',\n",
       " 'bay',\n",
       " 'sent',\n",
       " 'playing',\n",
       " 'past',\n",
       " 'bill',\n",
       " 'security',\n",
       " 'remains',\n",
       " 'economy',\n",
       " 'changes',\n",
       " 'wide',\n",
       " 'provide',\n",
       " 'saw',\n",
       " 'move',\n",
       " 'finally',\n",
       " 'gold',\n",
       " 'longer',\n",
       " 'physical',\n",
       " 'child',\n",
       " 'surface',\n",
       " 'square',\n",
       " 'spain',\n",
       " 'construction',\n",
       " 'summer',\n",
       " 'stage',\n",
       " 'mostly',\n",
       " 'hit',\n",
       " 'web',\n",
       " 'complex',\n",
       " 'greater',\n",
       " 'majority',\n",
       " 'already',\n",
       " 'notable',\n",
       " 'whom',\n",
       " 'enough',\n",
       " 'domain',\n",
       " 'recorded',\n",
       " 'mid',\n",
       " 'z',\n",
       " 'done',\n",
       " 'internet',\n",
       " 'companies',\n",
       " 'studies',\n",
       " 'refer',\n",
       " 'makes',\n",
       " 'believed',\n",
       " 'mark',\n",
       " 'woman',\n",
       " 'method',\n",
       " 'course',\n",
       " 'examples',\n",
       " 'male',\n",
       " 'deleted',\n",
       " 'contains',\n",
       " 'caused',\n",
       " 'primary',\n",
       " 'changed',\n",
       " 'things',\n",
       " 'magazine',\n",
       " 'operation',\n",
       " 'specific',\n",
       " 'replaced',\n",
       " 'mary',\n",
       " 'nation',\n",
       " 'turn',\n",
       " 'edition',\n",
       " 'russia',\n",
       " 'territory',\n",
       " 'edward',\n",
       " 'added',\n",
       " 'whole',\n",
       " 'involved',\n",
       " 'smith',\n",
       " 'idea',\n",
       " 'ten',\n",
       " 'cover',\n",
       " 'etc',\n",
       " 'dutch',\n",
       " 'perhaps',\n",
       " 'le',\n",
       " 'jersey',\n",
       " 'say',\n",
       " 'appears',\n",
       " 'dead',\n",
       " 'sense',\n",
       " 'separate',\n",
       " 'blood',\n",
       " 'carolina',\n",
       " 'length',\n",
       " 'philosophy',\n",
       " 'basic',\n",
       " 'entire',\n",
       " 'attempt',\n",
       " 'cannot',\n",
       " 'joseph',\n",
       " 'online',\n",
       " 'mountain',\n",
       " 'bank',\n",
       " 'oil',\n",
       " 'provided',\n",
       " 'rest',\n",
       " 'pope',\n",
       " 'israel',\n",
       " 'effects',\n",
       " 'sources',\n",
       " 'towards',\n",
       " 'sold',\n",
       " 'stories',\n",
       " 'independence',\n",
       " 'route',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve todas las palabras del vocabulario, ordenadas por frecuencia decreciente. Podemos obtener tamibén la palabra vector mediante la siguiente línea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02632042, -0.24961016, -0.03810176, -0.08363393,  0.17189504,\n",
       "        0.17880219,  0.1072038 ,  0.15014821,  0.1954687 ,  0.01911135,\n",
       "       -0.04647756, -0.00761587, -0.13115846,  0.1712115 ,  0.09849525,\n",
       "        0.06910376, -0.13694933,  0.15284032, -0.28793445,  0.10451043,\n",
       "        0.1526004 ,  0.32726157,  0.19839802, -0.06864461, -0.09726731,\n",
       "        0.02672472,  0.05838011,  0.46633056, -0.22053744, -0.10376953,\n",
       "        0.01865205,  0.17347327, -0.2944164 , -0.10139454,  0.02832289,\n",
       "        0.22598654,  0.17671743, -0.2040942 , -0.29931232,  0.08886325,\n",
       "       -0.02379124,  0.03572726, -0.18761243, -0.07018941,  0.11839328,\n",
       "       -0.13705416,  0.18952958,  0.01830937,  0.16742   ,  0.0677211 ,\n",
       "       -0.03569897,  0.19195762,  0.14106458, -0.15976259,  0.23845533,\n",
       "       -0.03598373, -0.1233262 ,  0.2336837 ,  0.18061058,  0.24142714,\n",
       "       -0.1091122 ,  0.1610991 ,  0.12832   , -0.00399957, -0.03390944,\n",
       "       -0.36903015,  0.20828909, -0.05053389, -0.1125346 , -0.17910154,\n",
       "       -0.00162836, -0.26417574,  0.10897855, -0.09083495, -0.29349872,\n",
       "        0.01115475,  0.15756671,  0.22695275,  0.10695632, -0.0996858 ,\n",
       "        0.05719158, -0.18232745,  0.13189302, -0.21653908,  0.18743429,\n",
       "       -0.11698267,  0.0466267 ,  0.01130395, -0.55757296, -0.20678611,\n",
       "        0.10681864, -0.0202413 ,  0.31041977, -0.12390548, -0.19429286,\n",
       "       -0.45627967,  0.06017311,  0.01062817, -0.0131738 , -0.06606922],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo deseamos podemos guardar este modelo en el disco como un archivo binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"wiki.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y recargarlo cuando queramos en vze de entrenar nuevamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(\"wiki.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con los parámetros\n",
    "\n",
    "Hasta ahora, ejecutamos fastText con los parámetros predeterminados, pero dependiendo de los datos, estos parámetros pueden no ser óptimos. Como explicamos en al teórica, algunos de estos parámetros son importantes y tienen una considerable influencia en nuestro modelo final.\n",
    "\n",
    "Los parámetros más importantes del modelo son su dimensión y el rango de tamaño de las subpalabras. La dimensión (dim) controla el tamaño de los vectores, cuanto más grandes son, más información pueden capturar, pero requiere que se aprendan más datos. Pero, si son demasiado grandes, son más difíciles y lentos de entrenar. De forma predeterminada, usamos 100 dimensiones, pero cualquier valor en el rango de 100 a 300 es igual de popular. Las subpalabras son todas las subcadenas contenidas en una palabra entre el tamaño mínimo (minn) y el tamaño máximo (maxn). Por defecto, tomamos todas las subpalabras entre 3 y 6 caracteres, pero otro rango podría ser más apropiado para diferentes idiomas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('data/fil9', minn=2, maxn=5, dim=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de la cantidad de datos que tenga, es posible que desee cambiar los parámetros del entrenamiento. El parámetro epoch controla cuántas veces el modelo recorrerá sus datos. De forma predeterminada, recorremos el conjunto de datos 5 veces. Si el conjunto de datos es extremadamente masivo, es posible que desee recorrerlo con menos frecuencia. \n",
    "\n",
    "Otro parámetro importante es la tasa de aprendizaje lr. Cuanto mayor sea la tasa de aprendizaje, más rápido convergerá el modelo a una solución, pero corremos el riesgo de sobreajustarse al conjunto de datos. El valor predeterminado es 0.05, que es un buen tradeoff. Si quieren jugar con él, les sugerimos que se mantengan en el rango de \\[0.01, 1\\]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('data/fil9', epoch=1, lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, FastText es multiproceso y usa 12 cores por defecto. Si tiene menos núcleos nuestro CPU (digamos 4), puede establecer fácilmente el número de subprocesos utilizando el flag thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('data/fil9', thread=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imprimiendo los word vectors\n",
    "\n",
    "Buscar e imprimir los word vectors directamente desde el archivo fil9.vec es engorroso. Afortunadamente, hay una funcionalidad de hacerlo en fastText.\n",
    "\n",
    "Por ejemplo, podemos imprimir los wordvectors de las palabras  asparagus, pidgey and yellow con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01506518,  0.4541949 ,  0.19321598,  0.5288826 , -0.42807326,\n",
       "        -0.30431366, -0.17672932,  0.40030366, -0.40666378, -0.03253674,\n",
       "         0.30891153,  0.08248681, -0.40068316,  0.5158829 ,  0.2209085 ,\n",
       "         0.4941609 , -0.38837457, -0.15517345, -0.13741846, -0.18254507,\n",
       "        -0.3497715 ,  0.7594063 , -0.36996326, -0.1199929 , -0.52514315,\n",
       "         0.5830892 ,  0.07602929,  0.45518115, -0.31864527, -0.5182843 ,\n",
       "         0.44003353, -0.2759131 , -0.7020693 ,  0.49431813, -0.29585573,\n",
       "         0.21835111,  0.68666893, -0.06382492,  0.39405414, -0.39237866,\n",
       "         0.28952232, -0.66669345, -0.5487205 ,  0.3580609 ,  0.35222614,\n",
       "        -0.48933667,  0.27267668,  0.06543619,  0.44272575, -0.358011  ,\n",
       "         0.1707241 ,  0.23901255,  0.30167413,  0.01029939, -0.04695751,\n",
       "        -0.2618878 , -0.08864275,  0.2924017 ,  0.20568264,  0.49246463,\n",
       "        -0.6709726 ,  0.19605027, -0.50157964, -0.09929345, -0.18812884,\n",
       "        -0.11779808, -0.04046599,  0.3065234 , -0.03036462,  0.04809628,\n",
       "         0.1329298 , -0.40646234, -0.06329256, -0.13394374, -0.05498753,\n",
       "         0.22398674,  0.3855192 ,  0.38433394,  0.29774177,  0.38125712,\n",
       "        -0.397007  , -0.15896596,  0.10577954, -0.15840468,  0.3377056 ,\n",
       "        -0.12444165,  0.13276722,  0.34744   ,  0.13897659, -0.56435555,\n",
       "         0.47064665,  0.5170303 ,  0.19127221, -0.29835793, -0.2917991 ,\n",
       "        -0.6000742 ,  0.40245798,  0.08902264,  0.2837244 ,  0.13712141],\n",
       "       dtype=float32),\n",
       " array([ 0.14217773,  0.66184145, -0.11828583,  0.09634852, -0.32205844,\n",
       "         0.1811713 , -0.05688215,  0.48149753,  0.24329945,  0.33813262,\n",
       "        -0.11469088,  0.21525624, -0.21543473, -0.29727152, -0.18126507,\n",
       "         0.15245336,  0.35285315, -0.1520965 ,  0.0108927 , -0.1103839 ,\n",
       "        -0.14955151,  0.5421718 , -0.669124  ,  0.09475083, -0.21283084,\n",
       "         0.02673919, -0.31782347,  0.5014237 , -0.65430254, -0.0464835 ,\n",
       "         0.289581  ,  0.19808747,  0.26593634, -0.08009761, -0.19616847,\n",
       "        -0.45714107,  0.7265298 ,  0.31181392,  0.17965016,  0.00312397,\n",
       "        -0.20918569,  0.18627332,  0.09931507,  0.29898146,  0.2985378 ,\n",
       "        -0.6668007 ,  0.11977135,  0.4838121 , -0.05619665,  0.19763769,\n",
       "        -0.631437  ,  0.06128671,  0.485152  , -0.31111044,  0.71517485,\n",
       "         0.1869312 , -0.18502256,  0.30441138,  0.49803188,  0.456197  ,\n",
       "        -0.17502636,  0.31233427,  0.07450518, -0.02225444,  0.30562538,\n",
       "         0.06943646, -0.25592718,  0.53508776, -0.2717402 , -0.4899576 ,\n",
       "         0.18086037, -0.58456004,  0.07536893,  0.426261  , -0.3288323 ,\n",
       "         0.75720483,  0.23209514,  0.05818329,  0.40487918,  0.53428054,\n",
       "         0.14336458, -0.50135463, -0.17891234,  0.00922036,  0.16869596,\n",
       "        -0.41959506,  0.19568896,  0.6529065 ,  0.18514597,  0.14682433,\n",
       "         0.13025665,  0.04427499,  0.40299314, -0.18988447, -0.35062084,\n",
       "        -0.06964046, -0.3053858 ,  0.21346547,  0.24612622,  0.17379345],\n",
       "       dtype=float32),\n",
       " array([-1.30948797e-01, -1.02420896e-01,  1.03735223e-01,  1.72319070e-01,\n",
       "        -2.62175918e-01,  2.26210147e-01,  1.07677735e-01,  6.83627844e-01,\n",
       "         3.14225703e-01,  2.00018827e-02,  3.14529777e-01,  1.15098637e-02,\n",
       "        -5.26112840e-02, -2.68062651e-01,  3.77007306e-01,  4.83483970e-01,\n",
       "        -2.56871104e-01,  1.97599933e-01, -1.55527994e-01, -2.48462200e-01,\n",
       "         1.06053181e-01,  2.25369126e-01,  3.74328107e-01, -7.19994754e-02,\n",
       "        -7.90899470e-02, -6.00326419e-01, -3.17292601e-01,  1.60921082e-01,\n",
       "        -4.67329234e-01, -6.46029711e-01,  3.42520565e-01,  2.46907368e-01,\n",
       "        -2.71373302e-01,  1.42011017e-01, -5.68480015e-01, -1.05958313e-01,\n",
       "         2.12960690e-01, -1.69469833e-01,  6.89896941e-02, -3.47881794e-01,\n",
       "        -5.40257208e-02, -3.73281270e-01, -3.30555439e-01, -9.67810676e-02,\n",
       "         8.37434083e-02, -6.11155093e-01,  3.67144525e-01, -7.50901639e-01,\n",
       "        -1.44483596e-01,  1.98970605e-02, -3.82470787e-01,  8.14215243e-01,\n",
       "         4.86832261e-01, -4.25950479e-04,  5.41759372e-01, -8.03244188e-02,\n",
       "        -4.61885512e-01,  2.96908975e-01,  3.66010159e-01,  2.67026633e-01,\n",
       "        -3.99829179e-01,  6.02042973e-01,  3.81926119e-01, -5.25389537e-02,\n",
       "        -9.27998945e-02,  2.37526491e-01,  7.18765929e-02, -2.70195067e-01,\n",
       "        -2.67409950e-01, -3.37432176e-01, -5.99744380e-01, -8.33585262e-01,\n",
       "        -5.66763394e-02,  2.41479024e-01,  2.26016805e-01,  4.48901594e-01,\n",
       "        -9.21850652e-02,  5.37638605e-01,  3.41356844e-01,  1.52946532e-01,\n",
       "        -7.64715075e-02,  6.92496598e-02, -2.06204072e-01,  9.22790356e-03,\n",
       "         4.41529825e-02, -1.26314119e-01,  5.14387786e-02, -1.70918610e-02,\n",
       "         1.17129339e-02, -1.46225587e-01,  1.95611253e-01,  4.17908758e-01,\n",
       "         6.48088396e-01,  2.90722102e-01, -4.01327014e-01, -3.02455276e-02,\n",
       "         7.28772953e-02,  1.76881284e-01,  1.52616069e-01,  3.49590749e-01],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.get_word_vector(x) for x in [\"asparagus\", \"pidgey\", \"yellow\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una característica interesante es que también pueden consultar palabras que no aparecieron en sus datos. De hecho, las palabras están representadas por la suma de sus subcadenas. Siempre que la palabra desconocida esté formada por subcadenas conocidas, ¡hay una representación de ella!\n",
    "\n",
    "Como ejemplo, intentemos con una palabra mal escrita (enviroment en vez enviroNment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24546665,  0.17185892,  0.36975354,  0.15062103,  0.05924705,\n",
       "       -0.18265083,  0.20884101,  0.29403046,  0.26728413, -0.04502287,\n",
       "       -0.05671503,  0.31518966, -0.20782839,  0.05031516, -0.21250737,\n",
       "       -0.29691422, -0.22266586, -0.07359225,  0.19458035, -0.18314838,\n",
       "       -0.23749383,  0.39292747, -0.07799876, -0.2924569 , -0.20469038,\n",
       "        0.18595292, -0.10828631,  0.19247656, -0.04968495, -0.15305763,\n",
       "        0.17281617,  0.15498145, -0.16324265, -0.09012615, -0.10538822,\n",
       "        0.14633149,  0.4234822 ,  0.35851237, -0.21599425,  0.10492532,\n",
       "        0.12876286, -0.19906555, -0.3965619 ,  0.03541358,  0.35185996,\n",
       "       -0.23164453,  0.13202028, -0.47295228, -0.06744   ,  0.07074037,\n",
       "        0.07173958, -0.02897722,  0.17869046, -0.17137827,  0.40009668,\n",
       "        0.02940893,  0.17360994,  0.25939098, -0.00396638,  0.31027418,\n",
       "       -0.14148653,  0.45694497, -0.24414116, -0.09693296, -0.17908624,\n",
       "       -0.26552296,  0.31199968,  0.01826492,  0.11359236,  0.4749247 ,\n",
       "        0.12504837, -0.32205224,  0.05286374, -0.01749378, -0.43433794,\n",
       "       -0.21358551,  0.12215052,  0.47270557, -0.04192416, -0.30993745,\n",
       "        0.29235852, -0.23698893, -0.03830669,  0.00677039,  0.08623487,\n",
       "       -0.5226898 ,  0.04706835, -0.09343899, -0.63154316,  0.08669489,\n",
       "        0.09112564, -0.11996076,  0.05573012, -0.22198385,  0.16433205,\n",
       "       -0.02188735, -0.30000466,  0.2455984 , -0.03542423, -0.17543353],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(\"enviroment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Aún obtienes un word vector para ella! ¿Pero qué tan bueno es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor queries\n",
    "\n",
    "Una forma sencilla de comprobar la calidad de un word vector es mirar a sus vecinos más cercanos. Esto da una intuición del tipo de información semántica que los vectores son capaces de capturar.\n",
    "\n",
    "Se puede lograr con la funcionalidad de vecino más cercano (nn). Por ejemplo, podemos consultar los 10 vecinos más cercanos de la palabra asparagus (esparragos) ejecutando el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7928065657615662, 'spinach'),\n",
       " (0.7857974767684937, 'cabbage'),\n",
       " (0.7840216755867004, 'beetroot'),\n",
       " (0.7822654843330383, 'tomato'),\n",
       " (0.7815334796905518, 'asparagales'),\n",
       " (0.7767889499664307, 'beets'),\n",
       " (0.7748492956161499, 'cabbages'),\n",
       " (0.7702080607414246, 'horseradish'),\n",
       " (0.7677841186523438, 'lingonberries'),\n",
       " (0.7674185633659363, 'carrots')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('asparagus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Bien! Parece que los vectores de vegetales son similares. \n",
    "\n",
    "¿Qué pasa con los pokemons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9004228115081787, 'pidgeotto'),\n",
       " (0.8991588354110718, 'pidgeot'),\n",
       " (0.8793633580207825, 'pidge'),\n",
       " (0.7655767798423767, 'pikachu'),\n",
       " (0.7634807825088501, 'beedrill'),\n",
       " (0.7627153992652893, 'pidgeon'),\n",
       " (0.756135880947113, 'jigglypuff'),\n",
       " (0.7553478479385376, 'squirtle'),\n",
       " (0.746259868144989, 'pok'),\n",
       " (0.7327038645744324, 'charizard')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.get_nearest_neighbors('pidgey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Diferentes evoluciones del mismo Pokémon tienen vectores cercanos! \n",
    "\n",
    "¿Qué pasará con nuestra palabra mal escrita, su vector se acerca será algo razonable? Vamos a averiguarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8919543623924255, 'enviromental'),\n",
       " (0.8458593487739563, 'environ'),\n",
       " (0.8340750336647034, 'enviro'),\n",
       " (0.7590425610542297, 'environnement'),\n",
       " (0.7503014802932739, 'environs'),\n",
       " (0.7456784844398499, 'enviromission'),\n",
       " (0.7164572477340698, 'environment'),\n",
       " (0.6881601810455322, 'realclimate'),\n",
       " (0.6581783890724182, 'environmentally'),\n",
       " (0.6508368849754333, 'acclimatation')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('enviroment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a la información contenida en la palabra, el vector de nuestra palabra mal escrita coincide con palabras razonables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogías\n",
    "\n",
    "Con un espíritu similar, se puede jugar con analogías de palabras. Por ejemplo, podemos ver si nuestro modelo puede adivinar que palabra es para Argentina dado lo qué Berlín es para Alemania.\n",
    "\n",
    "Esto se puede hacer con la funcionalidad de analogías. Toma un triplete de palabras (como Alemania, Berlín, Argentina) y genera la analogía:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8049203157424927, 'buenos'),\n",
       " (0.7984284162521362, 'aires'),\n",
       " (0.7456688284873962, 'argentinas'),\n",
       " (0.7436091303825378, 'argentinos'),\n",
       " (0.739849865436554, 'argentinan'),\n",
       " (0.7182493805885315, 'argentine'),\n",
       " (0.7181199193000793, 'argentino'),\n",
       " (0.7162852883338928, 'costa'),\n",
       " (0.7085649371147156, 'caracas'),\n",
       " (0.7032025456428528, 'argentinean')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"berlin\", \"germany\", \"argentina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta que nos da nuestro modelo es Buenos y Aires, que es correcto. \n",
    "Echemos un vistazo a un ejemplo menos obvio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7334167957305908, 'gamecube'),\n",
       " (0.7265833020210266, 'gba'),\n",
       " (0.722352147102356, 'gameboy'),\n",
       " (0.7193081974983215, 'sega'),\n",
       " (0.7175946235656738, 'puyo'),\n",
       " (0.7135152220726013, 'dreamcast'),\n",
       " (0.7043899893760681, 'arcade'),\n",
       " (0.6925106644630432, 'wario'),\n",
       " (0.6905795335769653, 'psp'),\n",
       " (0.6879773139953613, 'nintendogs')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"psx\", \"sony\", \"nintendo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo considera que la analogía de nintendo con una psx es el gamecube, lo que parece razonable. Por supuesto, la calidad de las analogías depende del conjunto de datos utilizado para entrenar el modelo y uno solo puede esperar cubrir conceptos que esten en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6249924898147583, 'euramerica'),\n",
       " (0.6145680546760559, 'brazillia'),\n",
       " (0.605961799621582, 'guarany'),\n",
       " (0.6026880741119385, 'europeo'),\n",
       " (0.6024648547172546, 'argentina'),\n",
       " (0.5876622796058655, 'gasport'),\n",
       " (0.5858680009841919, 'netherlands'),\n",
       " (0.5822027325630188, 'uruguay'),\n",
       " (0.5817792415618896, 'esporte'),\n",
       " (0.5752928853034973, 'venezolano')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"usa\", \"bush\", \"brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de los n-gramas\n",
    "\n",
    "El uso de información a nivel de tokens es particularmente interesante para construir vectores para palabras desconocidas. Por ejemplo, la palabra gearshift (palanca de cambios) no existe en este dataset de Wikipedia, pero aún podemos consultar sus palabras existentes más cercanas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7920395135879517, 'driveshaft'),\n",
       " (0.7858796119689941, 'driveshafts'),\n",
       " (0.7773779630661011, 'gears'),\n",
       " (0.7700628042221069, 'gearing'),\n",
       " (0.7678226232528687, 'daisywheel'),\n",
       " (0.7628052830696106, 'flywheel'),\n",
       " (0.759106457233429, 'flywheels'),\n",
       " (0.7532490491867065, 'wheelsets'),\n",
       " (0.752494215965271, 'wheelset'),\n",
       " (0.7506456971168518, 'crankshaft')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('gearshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de las palabras devueltas comparten subcadenas sustanciales, pero algunas son bastante diferentes, como rueda cogwheel (engranaje). \n",
    "\n",
    "Ahora que hemos visto la importancia de la información de los tokens de ngrams para palabras desconocidas, veamos cómo se compara con un modelo que no usa información de subpalabras. Para entrenar un modelo sin subpalabras, simplemente llevamos el maxn a 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_subwords = fasttext.train_unsupervised('data/fil9', maxn=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar la diferencia, tomemos una palabra poco común en Wikipedia, como accomodation, que es un error ortográfico de accomModation. Aquí están los vecinos más cercanos obtenidos sin subpalabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7584854960441589, 'directgov'),\n",
       " (0.7546752691268921, 'sunnhordland'),\n",
       " (0.7497950792312622, 'massgov'),\n",
       " (0.749082088470459, 'agrotourism'),\n",
       " (0.747370183467865, 'accomodations'),\n",
       " (0.7438468933105469, 'whitepages'),\n",
       " (0.7434263825416565, 'jaring'),\n",
       " (0.7432680726051331, 'maranoa'),\n",
       " (0.7413424253463745, 'municipals'),\n",
       " (0.7408892512321472, 'radzima')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_without_subwords.get_nearest_neighbors('accomodation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado no tiene mucho sentido, la mayoría de estas palabras no están relacionadas. Por otro lado, el uso de información de subpalabras da la siguiente lista de vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9609587788581848, 'accomodations'),\n",
       " (0.9394452571868896, 'accommodation'),\n",
       " (0.917659342288971, 'accommodations'),\n",
       " (0.8432504534721375, 'accommodative'),\n",
       " (0.7997313737869263, 'accommodating'),\n",
       " (0.7738526463508606, 'lodging'),\n",
       " (0.7409136295318604, 'amenities'),\n",
       " (0.7281052470207214, 'catering'),\n",
       " (0.7241303324699402, 'hospitality'),\n",
       " (0.7029680013656616, 'accomodated')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('accomodation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vecinos más cercanos capturan diferentes variaciones en torno a la palabra alojamiento. También obtenemos palabras relacionadas semánticamente como amenities o catering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
